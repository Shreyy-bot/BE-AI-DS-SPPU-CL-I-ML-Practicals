{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61b63ec-a78e-4b70-b560-11e7b362290f",
   "metadata": {},
   "source": [
    "***Name: Sawant Shreyas Hanmant***\n",
    "\n",
    "***Roll No.: 2447046***\n",
    "\n",
    "***Batch: C***\n",
    "\n",
    "**Problem Statement ->**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4efb399-ef72-4095-b364-b8a6daa06a15",
   "metadata": {},
   "source": [
    "Build a Tic-Tac-Toe game using reinforcement\n",
    "learning in Python by using following\n",
    "tasks:-\n",
    "   \n",
    "    a. Setting up the environment\n",
    "    \n",
    "    b. Defining the Tic-Tac-Toe game\n",
    "    \n",
    "    c. Building the reinforcement learning model\n",
    "    \n",
    "    d. Training the model\n",
    "    \n",
    "    e. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb50ade-f015-488e-9d88-dbe211010794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827f1f27-1f0c-4cf5-b808-cf9b7e42499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d94559c-c2f8-4565-914b-e0bd6ebbf982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3))  # 3x3 board with zeros\n",
    "        self.done = False\n",
    "        self.winner = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3, 3))  # Reset the board\n",
    "        self.done = False\n",
    "        self.winner = None\n",
    "        return self.board\n",
    "\n",
    "    def available_actions(self):\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
    "\n",
    "    def take_action(self, action, player):\n",
    "        if self.board[action] == 0:\n",
    "            self.board[action] = player\n",
    "            if self.check_winner(player):\n",
    "                self.done = True\n",
    "                self.winner = player\n",
    "            elif len(self.available_actions()) == 0:  # Draw condition\n",
    "                self.done = True\n",
    "                self.winner = 0  # 0 indicates a draw\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def check_winner(self, player):\n",
    "        for i in range(3):\n",
    "            if all([self.board[i, j] == player for j in range(3)]) or all([self.board[j, i] == player for j in range(3)]):\n",
    "                return True\n",
    "        if all([self.board[i, i] == player for i in range(3)]) or all([self.board[i, 2 - i] == player for i in range(3)]):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def render(self):\n",
    "        print(self.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee5387b-45df-46f0-a09d-812d9eca88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, player, epsilon=0.1, alpha=0.5, gamma=0.9):\n",
    "        self.q_table = {}  # Stores Q-values\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.player = player\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((tuple(map(tuple, state)), action), 0)\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        best_next_q = max([self.get_q_value(next_state, a) for a in game.available_actions()], default=0)\n",
    "        current_q = self.get_q_value(state, action)\n",
    "        new_q = current_q + self.alpha * (reward + self.gamma * best_next_q - current_q)\n",
    "        self.q_table[(tuple(map(tuple, state)), action)] = new_q\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(game.available_actions())  # Explore: random action\n",
    "        else:\n",
    "            q_values = {action: self.get_q_value(state, action) for action in game.available_actions()}\n",
    "            return max(q_values, key=q_values.get)  # Exploit: best action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3fb386-b6d2-450d-9b0b-fcd157cb60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def play_game(agent1, agent2):\n",
    "    state = game.reset()\n",
    "    agents = {1: agent1, -1: agent2}\n",
    "    current_player = 1\n",
    "\n",
    "    while not game.done:\n",
    "        agent = agents[current_player]\n",
    "        action = agent.choose_action(state)\n",
    "        game.take_action(action, current_player)\n",
    "        next_state = game.board\n",
    "\n",
    "        if game.done:\n",
    "            if game.winner == 1:\n",
    "                agent1.update_q_value(state, action, 1, next_state)\n",
    "                agent2.update_q_value(state, action, -1, next_state)\n",
    "            elif game.winner == -1:\n",
    "                agent1.update_q_value(state, action, -1, next_state)\n",
    "                agent2.update_q_value(state, action, 1, next_state)\n",
    "            else:\n",
    "                agent1.update_q_value(state, action, 0.5, next_state)  # Draw reward\n",
    "                agent2.update_q_value(state, action, 0.5, next_state)\n",
    "        else:\n",
    "            agent1.update_q_value(state, action, 0, next_state)\n",
    "            agent2.update_q_value(state, action, 0, next_state)\n",
    "\n",
    "        state = next_state\n",
    "        current_player *= -1  # Switch player\n",
    "\n",
    "    return game.winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60cc0d91-6139-4d3b-99e8-e1ff7558d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interactive_game(agent, human_player):\n",
    "    state = game.reset()\n",
    "    current_player = 1  # X always starts first\n",
    "    \n",
    "    while not game.done:\n",
    "        game.render()\n",
    "        if current_player == human_player:\n",
    "            # Human's turn\n",
    "            action = tuple(map(int, input(\"Enter your move as 'row column' (e.g., 0 0): \").split()))\n",
    "            if action not in game.available_actions():\n",
    "                print(\"Invalid move. Try again.\")\n",
    "                continue\n",
    "        else:\n",
    "            # Agent's turn\n",
    "            print(\"AI is thinking...\")\n",
    "            action = agent.choose_action(state)\n",
    "\n",
    "        game.take_action(action, current_player)\n",
    "        state = game.board\n",
    "        current_player *= -1  # Switch turns\n",
    "\n",
    "    game.render()\n",
    "\n",
    "    if game.winner == human_player:\n",
    "        print(\"Congratulations! You won!\")\n",
    "    elif game.winner == -human_player:\n",
    "        print(\"You lost! The AI won.\")\n",
    "    else:\n",
    "        print(\"It's a draw!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6fe90a-3337-41aa-8521-dc5670e04fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = TicTacToe()\n",
    "agent_X = QLearningAgent(player=1)\n",
    "agent_O = QLearningAgent(player=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29013539-1be9-4f9b-91eb-ba852483ec12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Model has been trained. Now you can play with it or let two agents play.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for episode in range(10000):\n",
    "    play_game(agent_X, agent_O)\n",
    "\n",
    "# Testing the model\n",
    "game.reset()\n",
    "game.render()\n",
    "\n",
    "print(\"Model has been trained. Now you can play with it or let two agents play.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cadeed5-129e-47ae-8840-d2cccce91d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now, play against the AI!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to be X (1) or O (-1)?  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move as 'row column' (e.g., 0 0):  1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "AI is thinking...\n",
      "[[-1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move as 'row column' (e.g., 0 0):  2 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "AI is thinking...\n",
      "[[-1. -1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move as 'row column' (e.g., 0 0):  0 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "Congratulations! You won!\n"
     ]
    }
   ],
   "source": [
    "# Testing the model with human interaction\n",
    "print(\"\\nNow, play against the AI!\\n\")\n",
    "human_player = int(input(\"\\nDo you want to be X (1) or O (-1)? \"))\n",
    "\n",
    "if human_player == 1:\n",
    "    interactive_game(agent_O, 1)  # Human plays as X, AI as O\n",
    "else:\n",
    "    interactive_game(agent_X, -1)  # Human plays as O, AI as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500e311-e74e-48b8-9016-6e4befae7cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
